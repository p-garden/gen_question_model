{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0f9964-65eb-41c5-8c81-29580b876e25",
   "metadata": {},
   "source": [
    "- T5모델 (Text-to-Text Transfer Transformer)\n",
    "    - 입력텍스트, 태스크정의 를 입력하면 태스크에 맞게 입력텍스트로부터 동작을 수행\n",
    "    - 문제 생성, 오답선지 생성, 정답찾기등 다양한 태스크를 하나의 모델로 구축 가능\n",
    "\n",
    "입력 데이터 형식(텍스트 데이터 처리 결과):\n",
    "\n",
    " JSON형식으로 텍스트, 문장, 키워드등을 포함한 데이터 형식으로 입력받기\n",
    "\n",
    "출력 데이터 형식: \n",
    "\n",
    "출제된 문제와 자료토대로한 정답\n",
    "\n",
    "### **사전 학습된 모델 활용 + Few-shot Learning 전략**\n",
    "\n",
    "T5모델을 사용 (다양한 태스크를 하나의 모델로 통일)\n",
    "\n",
    "```json\n",
    "Task: [수행할 작업] Input: [처리할 텍스트]\n",
    "\t[작업]\n",
    "\t\"generate question:\" → 주어진 텍스트에서 질문 생성.\n",
    "\t\"summarize:\" → 텍스트 요약.\n",
    "\t\"translate English to French:\" → 영어 텍스트를 프랑스어로 번역.\n",
    "\t\"extract answer:\" → 지문에서 질문에 대한 정답 추출.\n",
    "\n",
    "```\n",
    "\n",
    "→이미 사전학습된 모델임 / 토큰화등 데이터 전처리 필요X (일반적인 전처리는 T5모델 내부에서 실행 특수문자 제거, 슬라이싱, 도메인특화 등등 특수한 전처리만 실행)\n",
    "\n",
    "초기 모델링시 몇개의 PDf파일로 FineTuning\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": \"generate question: The Eiffel Tower was completed in 1889.\",\n",
    "  \"output\": \"When was the Eiffel Tower completed?\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3bbe05-0129-490f-bb37-0d6ec2452066",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d442f1-b0ec-49f1-bfcb-43c4fa8954da",
   "metadata": {},
   "source": [
    "가상환경을 통한 환경설정  \n",
    "    cd C:\\Users\\j2982\\gen_question_env   \r",
    "    gen_question_env\\Scripts\\activate  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f050b345-7382-4b7e-af7b-282ccd29e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a2ed12-00f7-494f-b4ec-a6466a1aa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78c2fef-e38b-4c64-91ee-b88ad388a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WINDOWS\\system32\\gen_que_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb42328-7eea-48dd-a6cb-7e950bad3434",
   "metadata": {},
   "source": [
    "# 2. 모델, 토크나이저 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cfcc80-d3b7-471d-ae3d-8441d3c37209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b734d7a-c0f8-45f2-89a5-20d943f60e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12225819-ed59-4d61-b657-81ae24dd152f",
   "metadata": {},
   "source": [
    "# 3. 데이터준비(Fiine Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27cfd05-08f3-4c1f-b4af-b3fb668afeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8029e7b9-1773-4240-84fa-4fab21c02b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afefcd1c-b5ee-4817-a311-12db3c4bd1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate==0.30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60623638-9900-4d15-8b71-4f50def3ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27.2\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994c997e-cfed-4174-b417-3c3395722aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\j2982\\anaconda 3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bffbd8b-b95f-4d1a-8da7-b4048cf7588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers Version: 4.48.0\n",
      "Accelerate Version: 0.27.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "print(\"Transformers Version:\", transformers.__version__)\n",
    "print(\"Accelerate Version:\", accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c75dfa-343f-4834-b43a-35273f6b94fe",
   "metadata": {},
   "source": [
    "HuggingFace 코르쿼드(korQuad) 데이터셋 <PDF자료로 대체?>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f69c74-75a1-4a00-9330-6481f1b8e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"KorQuAD/squad_kor_v1\") #한국어 텍스트 데이터셋 지문,질문,답변으로 구성되어있음\n",
    "train_sampled = dataset['train'].select(range(1000))  # 처음 1000개 샘플 선택\n",
    "validation_sampled = dataset['validation'].select(range(200))  # 처음 200개 샘플 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a458e2-2623-414d-b095-9e3d4723beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 60407\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 5774\n",
      "    })\n",
      "})\n",
      "{'id': '6566495-0-0', 'title': '파우스트_서곡', 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.', 'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?', 'answers': {'text': ['교향곡'], 'answer_start': [54]}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "\n",
    "# 학습 데이터 샘플 출력\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b128025-3df4-4980-bb76-4b900039aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 432.52 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 469.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    #inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
    "    #targets = [a[\"text\"][0] if len(a[\"text\"]) > 0 else \"\" for a in examples[\"answers\"]]\n",
    "\n",
    "    inputs = [f\"context: {c}\" for c in examples[\"context\"]]\n",
    "\n",
    "    # 출력은 [질문]과 [답변]을 연결\n",
    "    targets = [\n",
    "        f\"{q} {a['text'][0]}\" if len(a[\"text\"]) > 0 else q\n",
    "        for q, a in zip(examples[\"question\"], examples[\"answers\"])\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # Tokenizer를 사용하여 입력과 출력 처리\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,  # 입력의 최대 길이\n",
    "        padding=\"max_length\",  # 패딩 활성화\n",
    "        truncation=True,  # 입력이 max_length보다 길면 잘라냄\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=128,  # 출력의 최대 길이\n",
    "        padding=\"max_length\",  # 패딩 활성화\n",
    "        truncation=True,  # 출력이 max_length보다 길면 잘라냄\n",
    "    )\n",
    "\n",
    "    # 모델 입력에 레이블 추가\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "train_dataset = train_sampled.map(preprocess_function, batched=True)\n",
    "validation_dataset = validation_sampled.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9638da6-e9b7-4a2d-b844-67b598d4f912",
   "metadata": {},
   "source": [
    "# 4. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d034044-a3c1-4ae9-be6b-ca7923a6ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44834e1a-a6a2-46b6-ba45-b451be3fe591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j2982\\AppData\\Local\\Temp\\ipykernel_21768\\1225819472.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_finetuned\",\n",
    "    evaluation_strategy=\"steps\",  # 평가를 steps 단위로 설정\n",
    "    save_strategy=\"steps\",        # 모델 저장도 steps 단위로 설정\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=500,               # 저장 간격\n",
    "    eval_steps=500,               # 평가 간격\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,  # 가장 좋은 모델 로드\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c44afe-3883-4d81-a595-f47c8893411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/250 00:38 < 2:38:44, 0.03 it/s, Epoch 0.02/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tuning 실행\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9d8ec-7bbd-40b2-8a69-9d344a023ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./korquad_t5_model\")\n",
    "tokenizer.save_pretrained(\"./korquad_t5_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0d865-e6b5-442c-8e06-e6035fd05b13",
   "metadata": {},
   "source": [
    "# 5. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c8cff-fc1b-4a8b-b1ae-14af0ab192db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 입력\n",
    "input_text = \"context: 서울은 대한민국의 수도로, 행정, 경제, 문화의 중심지이다.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# 질문과 답변 생성\n",
    "outputs = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "print(\"Generated Output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0dd81e-f92e-4924-8524-238d8a07fe6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gen_que_env)",
   "language": "python",
   "name": "gen_que_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
